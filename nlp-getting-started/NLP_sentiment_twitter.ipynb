{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cec09fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus.reader.wordnet import *\n",
    "import re\n",
    "import string\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915e6f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "worddict = set(nltk.corpus.words.words())\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = english_punctuations\n",
    "# def clean_text(text):\n",
    "#     return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", text).split())\n",
    "def merge_key_word_text(x,y):\n",
    "    tem=\"\"\n",
    "    if str(x)!='nan':\n",
    "        tem+=(str(x)+\" \")\n",
    "    return tem+str(y)\n",
    "def clean_text(text):\n",
    "    text= re.sub(\"'\", \"\", text)\n",
    "    text = re.sub('@[A-Za-z0-9_]+', '', text) #removes @mentions\n",
    "    text = re.sub('#','',text) #removes hastag '#' symbol\n",
    "    text = re.sub('RT[\\s]+','',text)\n",
    "    text = re.sub('https?:\\/\\/\\S+', '', text) \n",
    "    text = re.sub('\\n',' ',text)\n",
    "    tem=\"\".join([char for char in text if char not in string.punctuation])\n",
    "    clean_str = ''.join([c for c in tem if ord(c) < 128])\n",
    "    return clean_str\n",
    "def cleaning_numbers(data):\n",
    "    return re.sub('[0-9]+', '', data)\n",
    "def cleaning_repeating_char(text):\n",
    "    return re.sub(r'(.)\\1\\1+', r'\\1\\1', text)#(.)\\1{3,}\n",
    "def preprocessing(text):\n",
    "    new_text = clean_text(text.strip())\n",
    "    new_text = cleaning_numbers(new_text)\n",
    "    new_text = cleaning_repeating_char(new_text)\n",
    "    tokens = word_tokenize(new_text.lower())\n",
    "    new_text = \" \".join([wn.lemmatize(w) for w in tokens if not w in stop_words])\n",
    "    #text=\" \".join([wn.lemmatize(word) for word in word_tokenize(new_text)])\n",
    "    return new_text\n",
    "#     wordset_n = set(wn.lemmatize(w, NOUN) for w in word_tokenize(new_text.lower().strip()))\n",
    "#     wordset_v = set(wn.lemmatize(w, VERB) for w in wordset_n)\n",
    "#     wordset = set(wn.lemmatize(w, ADJ) for w in wordset_v)\n",
    "#     wordset = wordset & worddict\n",
    "#     return ' '.join(list(wordset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aefe0ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"train.csv\")\n",
    "data_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec3db2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['m_text']=data_train.apply(lambda row: merge_key_word_text(row['keyword'],row['text']),axis=1)\n",
    "data_test['m_text']=data_test.apply(lambda row: merge_key_word_text(row['keyword'],row['text']),axis=1)\n",
    "data_train['new_text']=data_train['m_text'].apply(lambda x: preprocessing(x))\n",
    "data_test['new_text']=data_test['m_text'].apply(lambda x: preprocessing(x))\n",
    "data_train.to_csv('tem.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87dbe4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "features='new_text'#['new_text','keyword_target','location_clean_target']\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data_train[features],\n",
    "    data_train['target'],stratify=data_train['target'],\n",
    "    test_size=0.2,\n",
    "    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "411036d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word',max_df=0.95)\n",
    "x_train_tf = tfidf_vect.fit_transform(x_train)\n",
    "x_pre_tf = tfidf_vect.transform(x_test)\n",
    "x_test_tf = tfidf_vect.transform(data_test['new_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec8bdd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.84       869\n",
      "           1       0.86      0.66      0.74       654\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.82      0.79      0.79      1523\n",
      "weighted avg       0.81      0.80      0.80      1523\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8049901510177282"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# m_NB = MultinomialNB(alpha=1, fit_prior=True, class_prior=None)\n",
    "# m_NB\n",
    "BNBmodel = BernoulliNB(alpha=1.1, fit_prior=True, class_prior=None)\n",
    "BNBmodel.fit(x_train_tf, y_train) # train the classifier\n",
    "\n",
    "# convert list to matrix\n",
    "# tem=x_test[['keyword_target','location_clean_target']]\n",
    "# x_pre_f=pd.DataFrame(x_pre_tf.toarray(), columns=tfidf_vect.get_feature_names_out(),index=tem.index)\n",
    "# x_pre_f=pd.concat([x_pre_f,tem],axis=1)\n",
    "predicted = BNBmodel.predict(x_pre_tf)\n",
    "cr5    = classification_report(y_test,predicted)\n",
    "print(cr5)\n",
    "metrics.accuracy_score(list(y_test), predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd191e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[797,  72],\n",
       "       [225, 429]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(list(y_test), predicted)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "893e9822",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted =BNBmodel.predict(x_test_tf)\n",
    "pd.DataFrame({'id':data_test['id'],'target':predicted}).to_csv('submission_b_nb.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af549b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       869\n",
      "           1       0.81      0.69      0.74       654\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.80      0.78      0.79      1523\n",
      "weighted avg       0.80      0.80      0.79      1523\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7964543663821405"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_l =LogisticRegression() #LogisticRegression(C=0.7,solver='lbfgs',fit_intercept=False)#model_l = LogisticRegression(C=1.2)\n",
    "model_l.fit(x_train_tf, y_train)\n",
    "predicted = model_l.predict(x_pre_tf)\n",
    "cr5    = classification_report(y_test,predicted)\n",
    "print(cr5)\n",
    "metrics.accuracy_score(list(y_test), predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53866048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sajin.LAPTOP-RE0DL8PH\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "110 fits failed out of a total of 440.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "110 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sajin.LAPTOP-RE0DL8PH\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sajin.LAPTOP-RE0DL8PH\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Sajin.LAPTOP-RE0DL8PH\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Sajin.LAPTOP-RE0DL8PH\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.76896552 0.78981938 0.78965517        nan 0.76847291\n",
      " 0.79688013 0.79655172        nan 0.76880131 0.78998358 0.78981938\n",
      "        nan 0.76945813 0.79638752 0.79638752        nan 0.77044335\n",
      " 0.7908046  0.7908046         nan 0.77110016 0.79688013 0.79671593\n",
      "        nan 0.772578   0.79228243 0.79228243        nan 0.77175698\n",
      " 0.79770115 0.79737274        nan 0.77438424 0.79178982 0.79178982\n",
      "        nan 0.77356322 0.79753695 0.79753695        nan 0.77438424\n",
      " 0.79195402 0.79195402        nan 0.77356322 0.79737274 0.79737274\n",
      "        nan 0.77586207 0.79178982 0.79178982        nan 0.77405583\n",
      " 0.79720854 0.79720854        nan 0.77701149 0.79195402 0.79211823\n",
      "        nan 0.77504105 0.79737274 0.79737274        nan 0.7771757\n",
      " 0.79228243 0.79228243        nan 0.77569787 0.79802956 0.79835796\n",
      "        nan 0.7771757  0.79178982 0.79178982        nan 0.77520525\n",
      " 0.79868637 0.79852217        nan 0.77816092 0.79228243 0.79228243\n",
      "        nan 0.77536946 0.79835796 0.79835796]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       869\n",
      "           1       0.81      0.69      0.74       654\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.80      0.78      0.79      1523\n",
      "weighted avg       0.80      0.80      0.79      1523\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7964543663821405"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "hyperparameters = {\n",
    "    'solver':['lbfgs', 'liblinear'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [1,1.05,1.1,1.15,1.2,1.25,1.3,1.35,1.4,1.45,1.5],\n",
    "    'class_weight':['balanced',None]\n",
    "}\n",
    "model = LogisticRegression()\n",
    "grid_search = GridSearchCV(model, hyperparameters, cv=5)\n",
    "grid_search.fit(x_train_tf, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(x_pre_tf)\n",
    "cr5    = classification_report(y_test,predicted)\n",
    "print(cr5)\n",
    "metrics.accuracy_score(list(y_test), predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b00d632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[765, 104],\n",
       "       [206, 448]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(list(y_test), predicted)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fee329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = best_model.predict(x_test_tf)\n",
    "pd.DataFrame({'id':data_test['id'],'target':predicted}).to_csv('submission_cv_log.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b1b3ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       869\n",
      "           1       0.76      0.75      0.75       654\n",
      "\n",
      "    accuracy                           0.79      1523\n",
      "   macro avg       0.79      0.79      0.79      1523\n",
      "weighted avg       0.79      0.79      0.79      1523\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7898883782009193"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_l =LogisticRegression(C=1.15,solver='liblinear',class_weight='balanced') #LogisticRegression(C=0.7,solver='lbfgs',fit_intercept=False)#model_l = LogisticRegression(C=1.2)\n",
    "model_l.fit(x_train_tf, y_train)\n",
    "predicted = model_l.predict(x_pre_tf)\n",
    "cr5    = classification_report(y_test,predicted)\n",
    "print(cr5)\n",
    "metrics.accuracy_score(list(y_test), predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f89769a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[710, 159],\n",
       "       [161, 493]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(list(y_test), predicted)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cee90287",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model_l.predict(x_test_tf)\n",
    "pd.DataFrame({'id':data_test['id'],'target':predicted}).to_csv('submission_l_log.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3bff9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90      2084\n",
      "           1       0.86      0.77      0.81      1179\n",
      "\n",
      "    accuracy                           0.87      3263\n",
      "   macro avg       0.87      0.85      0.86      3263\n",
      "weighted avg       0.87      0.87      0.87      3263\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8119429590017826"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tem=pd.read_csv('submission_b_nb.csv')\n",
    "tem_2=pd.read_csv('model_submission.csv')\n",
    "c5=classification_report(tem_2[['target']],tem[['target']])\n",
    "print(c5)\n",
    "sklearn.metrics.f1_score(tem_2[['target']],tem[['target']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b79a64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      2084\n",
      "           1       0.79      0.79      0.79      1179\n",
      "\n",
      "    accuracy                           0.85      3263\n",
      "   macro avg       0.83      0.84      0.84      3263\n",
      "weighted avg       0.85      0.85      0.85      3263\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7900295732995354"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tem_3=pd.read_csv('submission_cv_log.csv')\n",
    "c5=classification_report(tem_2[['target']],tem_3[['target']])\n",
    "print(c5)\n",
    "sklearn.metrics.f1_score(tem_2[['target']],tem_3[['target']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e883d15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.82      0.86      2084\n",
      "           1       0.72      0.84      0.78      1179\n",
      "\n",
      "    accuracy                           0.83      3263\n",
      "   macro avg       0.81      0.83      0.82      3263\n",
      "weighted avg       0.84      0.83      0.83      3263\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7776475185619383"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tem_4=pd.read_csv('submission_l_log.csv')\n",
    "c5=classification_report(tem_2[['target']],tem_4[['target']])\n",
    "print(c5)\n",
    "sklearn.metrics.f1_score(tem_2[['target']],tem_4[['target']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a0c692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
